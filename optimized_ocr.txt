import cv2
import os
import numpy as np
import logging
import re
import easyocr
from ultralytics import YOLO
from skimage import exposure

# ---------- CONFIG ---------- #
VIDEO_PATH = "/path/to/your/video.mp4"
OUTPUT_TXT_PATH = "/path/to/output/ocr_results.txt"
MODEL_PATH = "best2.pt"  # Optimized YOLOv8n engine for Jetson preferred
FRAME_SKIP = 20  # Increase if speed is critical
USE_GPU_EASYOCR = True  # Set False if GPU not working
POLYGON = np.array([[726,466], [1255,474], [1403,1046], [600, 1057]], dtype=np.int32)
# --------------------------- #

# Initialize Logger
logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s: %(message)s')

# Precomputed Kernel
MORPH_KERNEL = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))

# Preprocessing Steps
def apply_polygon_mask(frame):
    mask = np.zeros(frame.shape[:2], dtype=np.uint8)
    cv2.fillPoly(mask, [POLYGON], 255)
    return cv2.bitwise_and(frame, frame, mask=mask)

def extract_plate(image, box, margin=0.2):
    x1, y1, x2, y2 = map(int, box)
    h, w = image.shape[:2]
    dx, dy = int(margin * (x2 - x1)), int(margin * (y2 - y1))
    x1e, y1e, x2e, y2e = max(0, x1 - dx), max(0, y1 - dy), min(w, x2 + dx), min(h, y2 + dy)
    return image[y1e:y2e, x1e:x2e]

def quick_precheck(crop, threshold=0.01):
    gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)
    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    ratio = cv2.countNonZero(binary) / (binary.shape[0] * binary.shape[1])
    return ratio > threshold

def preprocess_image(img):
    denoised = cv2.fastNlMeansDenoisingColored(img, None, 7, 7, 5, 15)
    gray = cv2.cvtColor(denoised, cv2.COLOR_BGR2GRAY)
    gamma = 0.8 if np.mean(gray) < 100 else 1.2 if np.mean(gray) > 150 else 1.0
    adjusted = exposure.adjust_gamma(denoised, gamma)
    lab = cv2.cvtColor(adjusted, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    l = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4,4)).apply(l)
    lab = cv2.merge((l, a, b))
    enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
    hsv = cv2.cvtColor(enhanced, cv2.COLOR_BGR2HSV)
    mask = cv2.inRange(hsv, (0,0,180), (180,50,255))
    non_white = cv2.bitwise_not(mask)
    filtered = cv2.bitwise_and(enhanced, enhanced, mask=non_white)
    thresh_gray = cv2.cvtColor(filtered, cv2.COLOR_BGR2GRAY)
    bilateral = cv2.bilateralFilter(thresh_gray, 7, 50, 50)
    thresh = cv2.adaptiveThreshold(bilateral, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 15, 9)
    cleaned = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, MORPH_KERNEL)
    sharpen_kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], np.float32)
    sharpened = cv2.filter2D(cleaned, -1, sharpen_kernel)
    return sharpened

# OCR Utilities
def find_rotation_angle(img):
    gray = img if len(img.shape) == 2 else cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    _, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)
    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if not contours:
        return 0.0
    rect = cv2.minAreaRect(max(contours, key=cv2.contourArea))
    angle = rect[-1]
    return 90 + angle if angle < -45 else -angle

def rotate_image(img, angle):
    (h, w) = img.shape[:2]
    M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)
    return cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REPLICATE)

def run_easyocr(img, reader, pattern):
    results = reader.readtext(img, detail=1, paragraph=False, decoder='greedy')
    return [text.strip().replace(" ", "") for (_, text, _) in results if pattern.match(text.strip().replace(" ", ""))]

# Main Jetson Nano Optimized Loop
def main():
    model = YOLO(MODEL_PATH)
    reader = easyocr.Reader(['en'], gpu=USE_GPU_EASYOCR, verbose=False)
    pattern = re.compile(r'^(0[1-9]|[1-6]\d|70)$')
    cap = cv2.VideoCapture(VIDEO_PATH)
    if not cap.isOpened():
        logging.error("Unable to open video.")
        return

    frame_count = 0
    detected_results = []

    while True:
        ret, frame = cap.read()
        if not ret:
            break
        if frame_count % FRAME_SKIP != 0:
            frame_count += 1
            continue

        masked = apply_polygon_mask(frame)
        results = model(masked)
        for res in results:
            for i, box in enumerate(res.boxes.xyxy):
                if int(res.boxes.cls[i]) != 1:
                    continue
                box = box.cpu().numpy()
                cx, cy = int((box[0] + box[2]) / 2), int((box[1] + box[3]) / 2)
                if cv2.pointPolygonTest(POLYGON, (cx, cy), False) < 0:
                    continue
                crop = extract_plate(frame, box)
                if crop is None or not quick_precheck(crop):
                    continue
                processed = preprocess_image(crop)
                angle = find_rotation_angle(processed)
                best_texts = []
                for offset in [-10, -5, 0, 5, 10]:
                    rotated = rotate_image(processed, angle + offset)
                    texts = run_easyocr(rotated, reader, pattern)
                    if len(texts) > len(best_texts):
                        best_texts = texts
                    if len(best_texts) >= 2:
                        break
                if best_texts:
                    result_str = f"Frame {frame_count} | Plate #{i} | Digits: {', '.join(best_texts)}"
                    logging.info(result_str)
                    detected_results.append(result_str)

        frame_count += 1

    cap.release()
    with open(OUTPUT_TXT_PATH, "w") as f:
        f.write("\n".join(detected_results))
    logging.info(f"Done. OCR results saved in: {OUTPUT_TXT_PATH}")

if __name__ == "__main__":
    main()
